{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gephify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import decimal\n",
    "\n",
    "# read car_models.csv\n",
    "df_models = pd.read_excel('car_models_edited.xlsx')\n",
    "#read brand_info.csv\n",
    "df_brand = pd.read_csv('brand_info.csv')\n",
    "#read sizing.xlsx\n",
    "df_sizing = pd.read_excel('sizing.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>review</th>\n",
       "      <th>make</th>\n",
       "      <th>extracted</th>\n",
       "      <th>make_description exist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACURA MDX</td>\n",
       "      <td>Reaching the 4th generation, the MDX became th...</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>{  \"car-model\": \"MDX\", \"year\": \"4th generation...</td>\n",
       "      <td>Innovative, Luxury, Sporty, Technological, Sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACURA RDX</td>\n",
       "      <td>Acura introduced a facelift for the third gene...</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>{  \"car-model\": \"RDX\",  \"year\": \"2022\",  \"type...</td>\n",
       "      <td>Innovative, Luxury, Sporty, Technological, Sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACURA TLX</td>\n",
       "      <td>No more drama and no more facelifted version f...</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>{  \"car-model\": \"Acura TLX\",  \"year\": \"2021\", ...</td>\n",
       "      <td>Innovative, Luxury, Sporty, Technological, Sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACURA ILX</td>\n",
       "      <td>The facelifted version of the ILX brought a sp...</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>{  \"car-model\": \"ILX\",  \"year\": \"facelifted ve...</td>\n",
       "      <td>Innovative, Luxury, Sporty, Technological, Sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACURA RLX</td>\n",
       "      <td>In 2017, Acura introduced the facelifted versi...</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>{  \"car-model\": \"RLX\",  \"year\": \"2017\",  \"type...</td>\n",
       "      <td>Innovative, Luxury, Sporty, Technological, Sle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model                                             review   make  \\\n",
       "0  ACURA MDX  Reaching the 4th generation, the MDX became th...  ACURA   \n",
       "1  ACURA RDX  Acura introduced a facelift for the third gene...  ACURA   \n",
       "2  ACURA TLX  No more drama and no more facelifted version f...  ACURA   \n",
       "3  ACURA ILX  The facelifted version of the ILX brought a sp...  ACURA   \n",
       "4  ACURA RLX  In 2017, Acura introduced the facelifted versi...  ACURA   \n",
       "\n",
       "                                           extracted  \\\n",
       "0  {  \"car-model\": \"MDX\", \"year\": \"4th generation...   \n",
       "1  {  \"car-model\": \"RDX\",  \"year\": \"2022\",  \"type...   \n",
       "2  {  \"car-model\": \"Acura TLX\",  \"year\": \"2021\", ...   \n",
       "3  {  \"car-model\": \"ILX\",  \"year\": \"facelifted ve...   \n",
       "4  {  \"car-model\": \"RLX\",  \"year\": \"2017\",  \"type...   \n",
       "\n",
       "                              make_description exist  \n",
       "0  Innovative, Luxury, Sporty, Technological, Sle...  \n",
       "1  Innovative, Luxury, Sporty, Technological, Sle...  \n",
       "2  Innovative, Luxury, Sporty, Technological, Sle...  \n",
       "3  Innovative, Luxury, Sporty, Technological, Sle...  \n",
       "4  Innovative, Luxury, Sporty, Technological, Sle...  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large\n"
     ]
    }
   ],
   "source": [
    "def converttoID(text):\n",
    "    # convert to lowercase\n",
    "    temp = text.lower()\n",
    "    #trim\n",
    "    temp = temp.strip()\n",
    "    # change space to dash\n",
    "    temp = temp.replace(' ', '-')\n",
    "    return temp\n",
    "\n",
    "\n",
    "def map_word_to_size(word, dataframe):\n",
    "    temp = word.lower()\n",
    "    temp = temp.strip()\n",
    "    for index, row in dataframe.iterrows():\n",
    "        #convert str to array of string\n",
    "        # print(row['bag'])\n",
    "        string = row['bag']\n",
    "        # print(string)\n",
    "        list = string.split(\", \")\n",
    "        # print(list)\n",
    "        if temp in list:\n",
    "            return row['sizes']\n",
    "    print(word,\" not found\")\n",
    "    return None\n",
    "\n",
    "print(map_word_to_size(\"SUV\", df_sizing))\n",
    "\n",
    "# sizes\tbag\n",
    "# small\tsmall, subcompact, hatchback, city car, supermini, kei class, open body\n",
    "# medium\tmedium, sedan, crossover, saloon, coupe, estate, roadster, compact, sports car, muscle car, supercar, hypercar, mid-size, gran touring, gt, grand tourer, mini suv, shooting brake\n",
    "# large\tlarge, suv, station wagon, estate, pickup truck, minivan, mpv, truck, van, minivan, super coupe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply map_word_to_size to df_models['extracted']\n",
    "df_models['sizing'] = df_models['extracted'].apply(lambda x: map_word_to_size(json.loads(x)['type'], df_sizing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>review</th>\n",
       "      <th>make</th>\n",
       "      <th>extracted</th>\n",
       "      <th>make_description exist</th>\n",
       "      <th>sizing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACURA MDX</td>\n",
       "      <td>Reaching the 4th generation, the MDX became th...</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>{  \"car-model\": \"MDX\", \"year\": \"4th generation...</td>\n",
       "      <td>Innovative, Luxury, Sporty, Technological, Sle...</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACURA RDX</td>\n",
       "      <td>Acura introduced a facelift for the third gene...</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>{  \"car-model\": \"RDX\",  \"year\": \"2022\",  \"type...</td>\n",
       "      <td>Innovative, Luxury, Sporty, Technological, Sle...</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACURA TLX</td>\n",
       "      <td>No more drama and no more facelifted version f...</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>{  \"car-model\": \"Acura TLX\",  \"year\": \"2021\", ...</td>\n",
       "      <td>Innovative, Luxury, Sporty, Technological, Sle...</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACURA ILX</td>\n",
       "      <td>The facelifted version of the ILX brought a sp...</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>{  \"car-model\": \"ILX\",  \"year\": \"facelifted ve...</td>\n",
       "      <td>Innovative, Luxury, Sporty, Technological, Sle...</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACURA RLX</td>\n",
       "      <td>In 2017, Acura introduced the facelifted versi...</td>\n",
       "      <td>ACURA</td>\n",
       "      <td>{  \"car-model\": \"RLX\",  \"year\": \"2017\",  \"type...</td>\n",
       "      <td>Innovative, Luxury, Sporty, Technological, Sle...</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model                                             review   make  \\\n",
       "0  ACURA MDX  Reaching the 4th generation, the MDX became th...  ACURA   \n",
       "1  ACURA RDX  Acura introduced a facelift for the third gene...  ACURA   \n",
       "2  ACURA TLX  No more drama and no more facelifted version f...  ACURA   \n",
       "3  ACURA ILX  The facelifted version of the ILX brought a sp...  ACURA   \n",
       "4  ACURA RLX  In 2017, Acura introduced the facelifted versi...  ACURA   \n",
       "\n",
       "                                           extracted  \\\n",
       "0  {  \"car-model\": \"MDX\", \"year\": \"4th generation...   \n",
       "1  {  \"car-model\": \"RDX\",  \"year\": \"2022\",  \"type...   \n",
       "2  {  \"car-model\": \"Acura TLX\",  \"year\": \"2021\", ...   \n",
       "3  {  \"car-model\": \"ILX\",  \"year\": \"facelifted ve...   \n",
       "4  {  \"car-model\": \"RLX\",  \"year\": \"2017\",  \"type...   \n",
       "\n",
       "                              make_description exist  sizing  \n",
       "0  Innovative, Luxury, Sporty, Technological, Sle...  medium  \n",
       "1  Innovative, Luxury, Sporty, Technological, Sle...  medium  \n",
       "2  Innovative, Luxury, Sporty, Technological, Sle...  medium  \n",
       "3  Innovative, Luxury, Sporty, Technological, Sle...  medium  \n",
       "4  Innovative, Luxury, Sporty, Technological, Sle...  medium  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model                                               DACIA Logan MCV Stepway\n",
       "review                    The Romanian car-maker Dacia had a big success...\n",
       "make                                                                  DACIA\n",
       "extracted                 {  \"car-model\": \"Logan MCV Stepway\",  \"year\": ...\n",
       "make_description exist           Vintage, Rugged, Cheap, Cheerful, Low-cost\n",
       "sizing                                                                large\n",
       "Name: 214, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models.iloc[214]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes + Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'acura', 'label': 'ACURA', 'group': 'make'}, {'id': 'alfa-romeo', 'label': 'ALFA ROMEO', 'group': 'make'}, {'id': 'alpine', 'label': 'ALPINE', 'group': 'make'}, {'id': 'ariel', 'label': 'ARIEL', 'group': 'make'}, {'id': 'aston-martin', 'label': 'ASTON MARTIN', 'group': 'make'}, {'id': 'audi', 'label': 'AUDI', 'group': 'make'}, {'id': 'bentley', 'label': 'BENTLEY', 'group': 'make'}, {'id': 'bmw', 'label': 'BMW', 'group': 'make'}, {'id': 'bufori', 'label': 'BUFORI', 'group': 'make'}, {'id': 'bugatti', 'label': 'BUGATTI', 'group': 'make'}, {'id': 'buick', 'label': 'BUICK', 'group': 'make'}, {'id': 'cadillac', 'label': 'CADILLAC', 'group': 'make'}, {'id': 'caterham', 'label': 'CATERHAM', 'group': 'make'}, {'id': 'chevrolet', 'label': 'CHEVROLET', 'group': 'make'}, {'id': 'chrysler', 'label': 'CHRYSLER', 'group': 'make'}, {'id': 'citroen', 'label': 'CITROEN', 'group': 'make'}, {'id': 'dacia', 'label': 'DACIA', 'group': 'make'}, {'id': 'daihatsu', 'label': 'DAIHATSU', 'group': 'make'}, {'id': 'datsun', 'label': 'DATSUN', 'group': 'make'}, {'id': 'dodge', 'label': 'DODGE', 'group': 'make'}, {'id': 'ferrari', 'label': 'FERRARI', 'group': 'make'}, {'id': 'fiat', 'label': 'FIAT', 'group': 'make'}, {'id': 'fisker', 'label': 'FISKER', 'group': 'make'}, {'id': 'ford', 'label': 'FORD', 'group': 'make'}, {'id': 'holden', 'label': 'HOLDEN', 'group': 'make'}, {'id': 'honda', 'label': 'HONDA', 'group': 'make'}, {'id': 'hyundai', 'label': 'HYUNDAI', 'group': 'make'}, {'id': 'ineos', 'label': 'INEOS', 'group': 'make'}, {'id': 'infiniti', 'label': 'INFINITI', 'group': 'make'}, {'id': 'jaguar', 'label': 'JAGUAR', 'group': 'make'}, {'id': 'jeep', 'label': 'JEEP', 'group': 'make'}, {'id': 'kia', 'label': 'KIA', 'group': 'make'}, {'id': 'koenigsegg', 'label': 'KOENIGSEGG', 'group': 'make'}, {'id': 'ktm', 'label': 'KTM', 'group': 'make'}, {'id': 'lada', 'label': 'LADA', 'group': 'make'}, {'id': 'lamborghini', 'label': 'LAMBORGHINI', 'group': 'make'}, {'id': 'lancia', 'label': 'LANCIA', 'group': 'make'}, {'id': 'land-rover', 'label': 'LAND ROVER', 'group': 'make'}, {'id': 'lexus', 'label': 'LEXUS', 'group': 'make'}, {'id': 'lightyear', 'label': 'LIGHTYEAR', 'group': 'make'}, {'id': 'lincoln', 'label': 'LINCOLN', 'group': 'make'}, {'id': 'lotus', 'label': 'LOTUS', 'group': 'make'}, {'id': 'maserati', 'label': 'MASERATI', 'group': 'make'}, {'id': 'mazda', 'label': 'MAZDA', 'group': 'make'}, {'id': 'mclaren', 'label': 'MCLAREN', 'group': 'make'}, {'id': 'mercedes-amg', 'label': 'MERCEDES-AMG', 'group': 'make'}, {'id': 'mercedes-benz', 'label': 'MERCEDES BENZ', 'group': 'make'}, {'id': 'mg', 'label': 'MG', 'group': 'make'}, {'id': 'mini', 'label': 'MINI', 'group': 'make'}, {'id': 'mitsubishi', 'label': 'MITSUBISHI', 'group': 'make'}, {'id': 'morgan', 'label': 'MORGAN', 'group': 'make'}, {'id': 'nio', 'label': 'NIO', 'group': 'make'}, {'id': 'nissan', 'label': 'NISSAN', 'group': 'make'}, {'id': 'opel', 'label': 'OPEL', 'group': 'make'}, {'id': 'pagani', 'label': 'PAGANI', 'group': 'make'}, {'id': 'panoz', 'label': 'PANOZ', 'group': 'make'}, {'id': 'perodua', 'label': 'PERODUA', 'group': 'make'}, {'id': 'peugeot', 'label': 'PEUGEOT', 'group': 'make'}, {'id': 'porsche', 'label': 'PORSCHE', 'group': 'make'}, {'id': 'renault', 'label': 'RENAULT', 'group': 'make'}, {'id': 'rimac', 'label': 'RIMAC', 'group': 'make'}, {'id': 'rolls-royce', 'label': 'ROLLS-ROYCE', 'group': 'make'}, {'id': 'seat', 'label': 'SEAT', 'group': 'make'}, {'id': 'skoda', 'label': 'SKODA', 'group': 'make'}, {'id': 'smart', 'label': 'SMART', 'group': 'make'}, {'id': 'spyker', 'label': 'SPYKER', 'group': 'make'}, {'id': 'subaru', 'label': 'SUBARU', 'group': 'make'}, {'id': 'suzuki', 'label': 'SUZUKI', 'group': 'make'}, {'id': 'toyota', 'label': 'TOYOTA', 'group': 'make'}, {'id': 'tvr', 'label': 'TVR', 'group': 'make'}, {'id': 'vauxhall', 'label': 'VAUXHALL', 'group': 'make'}, {'id': 'volkswagen', 'label': 'VOLKSWAGEN', 'group': 'make'}, {'id': 'volvo', 'label': 'VOLVO', 'group': 'make'}, {'id': 'wiesmann', 'label': 'WIESMANN', 'group': 'make'}, {'id': 'xpeng', 'label': 'XPENG', 'group': 'make'}, {'id': 'zenvo', 'label': 'ZENVO', 'group': 'make'}]\n"
     ]
    }
   ],
   "source": [
    "nodes_list = []\n",
    "edges_list = []\n",
    "#loop through make of df_models\n",
    "for make in df_models['make'].unique():\n",
    "    # print(make, df_models[df_models['make'] == make]['makeid'].iloc[0])\n",
    "    #add entry to nodes dataframe\n",
    "    nodes_list.append({'id': converttoID(make), 'label': make.upper(), 'group': 'make'})\n",
    "print(nodes_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model (not categorising by model because too large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #loop through model of df_models\n",
    "# for model in df_models['model'].unique():\n",
    "#     car_make = df_models[df_models['model'] == model]['make'].iloc[0]\n",
    "#     dict_string = df_models[df_models['model']==model]['extracted'].iloc[0]\n",
    "#     #add entry to nodes dataframe\n",
    "#     dict_extracted = json.loads(dict_string)\n",
    "#     car_model = dict_extracted['car-model']\n",
    "#     # print(car_model)\n",
    "#     car_type = dict_extracted['type']\n",
    "#     # adding model nodes\n",
    "#     nodes_list.append({'id': converttoID(car_model), 'label': car_model.upper(), 'group': 'car','type': converttoID(car_type)})\n",
    "\n",
    "#     # adding edges\n",
    "#     edges_list.append({'source': converttoID(car_make), 'target': converttoID(car_model), 'relationship': 'make of'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop each make\n",
    "for make in df_models['make'].unique():\n",
    "    # print(make,df_models[df_models['make'] == make]['sizing'])\n",
    "    # loop each size in 'make'\n",
    "    for size in df_models[df_models['make'] == make]['sizing'].unique():\n",
    "        # print(make, size)\n",
    "        # add entry to nodes dataframe\n",
    "        nodes_list.append({'id': converttoID(make+size), 'label': size.upper(), 'group': 'size'})\n",
    "        # adding edges\n",
    "        edges_list.append({'source': converttoID(make), 'target': converttoID(make+size), 'relationship': 'has_size'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_count = {\n",
    "        'count':{\n",
    "            \"windshield\": 1,\n",
    "            \"grille\": 1,\n",
    "            \"hood\": 1,\n",
    "            \"headlights\": 1,\n",
    "            \"bumper\": 1,\n",
    "            \"wheel\": 1,\n",
    "            \"doors\": 1,\n",
    "            \"roof\": 1,\n",
    "            \"diffusor\": 1,\n",
    "            \"spoiler\": 1,\n",
    "            \"exhaust\": 1\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# { \"car-model\": \"Artura\",\"year\": \"2021\",\"type\": \"supercar\",\"overall-design\": [\"aerodynamic\", \"revolutionary\", \"sporty\", \"compact\", \"electric\"],  \"design-elements\": {\"windshield\": [\"angled\"],\"grille\": [],\"hood\": [\"aerodynamic\"],\"headlights\": [\"angled\"],\"bumper\": [\"front\", \"deep air intakes\"],\"wheel\": [], \"doors\": [\"sporty\"], \"roof\": [\"lightweight\"],\"diffusor\": [],\"spoiler\": [],\"exhaust\": [\"hybrid\"]}}\n",
    "\n",
    "make_type_element_description_count = {}\n",
    "\n",
    "for model in df_models['model'].unique():\n",
    "    dict_string = df_models[df_models['model']==model]['extracted'].iloc[0]\n",
    "    #add entry to nodes dataframe\n",
    "    dict_extracted = json.loads(dict_string)\n",
    "    size = df_models[df_models['model']==model]['sizing'].iloc[0]\n",
    "    make = df_models[df_models['model']==model]['make'].iloc[0]\n",
    "\n",
    "    #check if the make & type exists in make_type_element_description_count dictionary\n",
    "    if make not in make_type_element_description_count:\n",
    "        make_type_element_description_count[make] = {}\n",
    "    if size not in make_type_element_description_count[make]:\n",
    "        make_type_element_description_count[make][size] = description_count.copy()\n",
    "    \n",
    "    # print(car_model)\n",
    "    design_elements = dict_extracted['design-elements']\n",
    "    for element in design_elements: # windshields, grille, hood, headlights, bumper, wheel, doors, roof, diffusor, spoiler, exhaust\n",
    "        if len(design_elements[element]) > 0: #if element has description\n",
    "            element_id = converttoID(make+size+element)\n",
    "            #check that the id of the dictionary in nodes_list \n",
    "            if any(d['id'] == element_id for d in nodes_list):\n",
    "            # if element_id not in nodes_list:\n",
    "                nodes_list.append({'id': element_id, 'label': element.upper(), 'group': 'element'})\n",
    "            for item in design_elements[element]:\n",
    "                count = make_type_element_description_count[make][size]['count'][element]\n",
    "                design_name = make+size+element+str(count)\n",
    "                # print(design_name)\n",
    "                nodes_list.append({'id': converttoID(design_name), 'label': item, 'group': 'description', 'element': element})\n",
    "                edges_list.append({'source': converttoID(make+size), 'target': element_id, 'relationship': 'has_element'})\n",
    "                edges_list.append({'source': element_id, 'target': converttoID(design_name), 'relationship': 'has_description'})\n",
    "                make_type_element_description_count[make][size]['count'][element] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design Style Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_style = pd.read_json('json/make_design.json')\n",
    "\n",
    "\n",
    "for make in df_models['make'].unique():\n",
    "    #find column in df_style\n",
    "    make_design = df_style[make]\n",
    "    # print(make_design)\n",
    "    labels = make_design.iloc[1]\n",
    "    scores = make_design.iloc[2]\n",
    "    # print(labels, scores)\n",
    "    for i in range(len(labels)):\n",
    "        emotion = labels[i]\n",
    "        score = scores[i]\n",
    "        decimalValue = decimal.Decimal(score)\n",
    "        roundedScore = decimalValue.quantize(decimal.Decimal('0.000'))\n",
    "        if make == 'ACURA': # only once, add nodes of emotions\n",
    "            nodes_list.append({'id': converttoID(emotion), 'label': emotion, 'group': 'emotion'})\n",
    "        # add edges\n",
    "        # if roundedScore > 0.10:\n",
    "        edges_list.append({'source': converttoID(emotion), 'target': converttoID(make), 'relationship': 'has_value', 'weight': roundedScore})\n",
    "        # edges_list.append({'source': converttoID(emotion), 'target': converttoID(make), 'relationship': 'has_value', 'weight': roundedScore})\n",
    "        # print(roundedScore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-car weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noncar\\7-eleven.csv\n",
      "7-eleven\n",
      "noncar\\adidas.csv\n",
      "adidas\n",
      "noncar\\apple.csv\n",
      "apple\n",
      "noncar\\daiso.csv\n",
      "daiso\n",
      "noncar\\levi.csv\n",
      "levi\n",
      "noncar\\louis vuitton.csv\n",
      "louis vuitton\n",
      "noncar\\nike.csv\n",
      "nike\n",
      "noncar\\rolex.csv\n",
      "rolex\n",
      "noncar\\victoria secret.csv\n",
      "victoria secret\n",
      "noncar\\xiaomi.csv\n",
      "xiaomi\n"
     ]
    }
   ],
   "source": [
    "# read each files in noncar folder\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import ast\n",
    "\n",
    "path = 'noncar/'\n",
    "\n",
    "for filename in glob.glob(os.path.join(path, '*.csv')):\n",
    "    print(filename)\n",
    "    # Define the regex pattern and search for it\n",
    "    match = re.search(r'noncar\\\\(.*?)\\.csv', filename)\n",
    "    extracted_text = ''\n",
    "    # Extract and print the matched group\n",
    "    if match:\n",
    "        extracted_text = match.group(1)\n",
    "        print(extracted_text)\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "    # print(df['score'].iloc[0])\n",
    "    scores_dict = ast.literal_eval(df['score'].iloc[0])\n",
    "    # print(scores_dict)\n",
    "    nodes_list.append({'id': converttoID(extracted_text), 'label': extracted_text, 'group': 'noncar'})\n",
    "    \n",
    "    for emotion, score in scores_dict.items():\n",
    "        decimalValue = decimal.Decimal(score)\n",
    "        roundedScore = decimalValue.quantize(decimal.Decimal('0.000'))\n",
    "        # add edges\n",
    "        # if roundedScore > 0.10:\n",
    "        edges_list.append({'source': converttoID(extracted_text), 'target': converttoID(emotion), 'relationship': 'has_value', 'weight': roundedScore})\n",
    "        # edges_list.append({'source': converttoID(emotion), 'target': converttoID(make), 'relationship': 'has_value', 'weight': roundedScore})\n",
    "        # print(roundedScore)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gephi Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df\n",
    "nodes = pd.DataFrame(nodes_list,columns=['id', 'label', 'group','element'])\n",
    "edges = pd.DataFrame(edges_list,columns=['source', 'target', 'relationship','weight'])\n",
    "\n",
    "#export as csv\n",
    "nodes.to_csv('gephi/nodes.csv', index=False)\n",
    "edges.to_csv('gephi/edges.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['make', 'size', 'description', 'emotion', 'noncar'], dtype=object)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes['group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_neo4j = {\n",
    "    \"make\": ['id', 'label', 'group'],\n",
    "    \"size\": ['id', 'label', 'group'],\n",
    "    \"element\": ['id', 'label', 'group'],\n",
    "    \"description\": ['id', 'label', 'group','element'],\n",
    "    \"emotion\": ['id', 'label', 'group'],\n",
    "    \"noncar\": ['id', 'label', 'group'],\n",
    "}\n",
    "\n",
    "edges_neo4j = {\n",
    "    \"has_size\": ['source', 'target', 'relationship'],\n",
    "    \"has_element\": ['source', 'target', 'relationship'],\n",
    "    \"has_description\": ['source', 'target', 'relationship'],\n",
    "    \"has_value\": ['source', 'target', 'relationship','weight'],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in nodes_neo4j.items():\n",
    "    nodes_make = nodes[nodes['group'] == key][value]\n",
    "    nodes_make = nodes_make.drop_duplicates()\n",
    "    nodes_make.to_csv(f'neo4j/{key}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in edges_neo4j.items():\n",
    "    edges_make = edges[edges['relationship'] == key][value]\n",
    "    #drop duplicates rows\n",
    "    edges_make = edges_make.drop_duplicates()\n",
    "    edges_make.to_csv(f'neo4j/{key}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4J Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:///make.csv' AS line\n",
    "CREATE (:make {key: line.id, name: (line.label)})\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:///size.csv' AS line\n",
    "CREATE (:size {key: line.id, name: (line.label)})\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:///element.csv' AS line\n",
    "CREATE (:element {key: line.id, name: (line.label)})\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:///description.csv' AS line\n",
    "CREATE (:description {key: line.id, name: (line.label)})\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:///emotion.csv' AS line\n",
    "CREATE (:emotion {key: line.id, name: (line.label)})\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:///noncar.csv' AS line\n",
    "CREATE (:noncar {key: line.id, name: (line.label)})\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM \"file:///has_size.csv\" AS line\n",
    "MATCH (p1:make {key:line.source})\n",
    "MATCH (p2:size {key:line.target})\n",
    "MERGE (p1)-[:HAS_SIZE]->(p2);\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM \"file:///has_element.csv\" AS line\n",
    "MATCH (p3:size {key:line.source})\n",
    "MATCH (p4:element {key:line.target})\n",
    "MERGE (p3)-[:HAS_ELEMENT]->(p4);\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM \"file:///has_description.csv\" AS line\n",
    "MATCH (p5:element {key:line.source})\n",
    "MATCH (p6:description {key:line.target})\n",
    "MERGE (p5)-[:HAS_DESCRIPTION]->(p6);\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM \"file:///has_value.csv\" AS line\n",
    "MATCH (p7:emotion {key:line.source})\n",
    "MATCH (p8:make {key:line.target})\n",
    "MERGE (p7)-[:HAS_VALUE {weight: toFloat(line.weight)}]->(p8);\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM \"file:///has_value.csv\" AS line\n",
    "MATCH (p9:noncar {key:line.source})\n",
    "MATCH (p10:emotion {key:line.target})\n",
    "MERGE (p9)-[:HAS_VALUE {weight: toFloat(line.weight)}]->(p10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query\n",
    "\n",
    "MATCH p=(make)-[r1:HAS_SIZE]->(size)-[r2:HAS_ELEMENT]->(element)-[r3:HAS_DESCRIPTION]->(description)\n",
    "where make.name = 'AUDI' return p LIMIT 50\n",
    "\n",
    "MATCH p=(emotion)-[r0:HAS_VALUE]->(make)-[r1:HAS_SIZE]->(size)-[r2:HAS_ELEMENT]->(element)-[r3:HAS_DESCRIPTION]->(description)\n",
    "where make.name = 'AUDI' return p LIMIT 50\n",
    "\n",
    "MATCH p=(noncar)-[r4:HAS_VALUE]->(emotion)-[r0:HAS_VALUE]->(make)-[r1:HAS_SIZE]->(size)-[r2:HAS_ELEMENT]->(element)-[r3:HAS_DESCRIPTION]->(description)\n",
    "where noncar.name = 'apple' return p LIMIT 50\n",
    "\n",
    "\n",
    "// Stage 1: Query Non-car brand and get the top 3 emotion weights\n",
    "MATCH (n:noncar {key: 'louis-vuitton'})-[r:HAS_VALUE]->(e:emotion)\n",
    "WHERE r.weight > 0.2\n",
    "WITH e, r.weight AS weight\n",
    "ORDER BY weight DESC\n",
    "LIMIT 3\n",
    "\n",
    "// Collect the top emotions and their weights\n",
    "WITH COLLECT(e) AS topEmotions, COLLECT(weight) AS topWeights, SUM(weight) AS totalWeight\n",
    "// Stage 2: Calculate the weight difference for each make\n",
    "UNWIND topEmotions AS topEmotion\n",
    "MATCH (topEmotion)-[r2:HAS_VALUE]->(m:make)\n",
    "WITH m, topEmotion, r2.weight AS makeWeight, topWeights, totalWeight\n",
    "ORDER BY m.name, topEmotion.name\n",
    "WITH m, SUM(makeWeight) AS totalMakeWeight, totalWeight, topWeights, COLLECT(topEmotion)[0..3] AS connectedEmotions\n",
    "ORDER BY ABS(totalWeight - totalMakeWeight)\n",
    "LIMIT 5\n",
    "\n",
    "// Stage 3: Find descriptions of design elements for each make, filtered by size and grouped by element\n",
    "MATCH (m)-[:HAS_SIZE]->(s:size {name: 'SMALL'})-[:HAS_ELEMENT]->(el:element)-[:HAS_DESCRIPTION]->(d:description)\n",
    "RETURN m.name AS ClosestMake, \n",
    "       [emotion IN connectedEmotions | emotion.name] AS TopEmotions,\n",
    "       ABS(totalWeight - totalMakeWeight) AS EmotionWeights,\n",
    "       el.name AS Element,\n",
    "       COLLECT(d.name) AS ElementDescriptions\n",
    "ORDER BY EmotionWeights\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscrapy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
